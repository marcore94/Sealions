{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from skimage.transform import rotate, resize, SimilarityTransform, warp\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define in advance constants to build the model\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "IM_HEIGHT = 96\n",
    "IM_WIDTH = 96\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIMIZER = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "SL_TRAIN_SIZE = 50121\n",
    "SL_VALIDATION_SIZE = 12531\n",
    "SL_TEST_SIZE = 17634\n",
    "EPOCHS = 40\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "STEPS_PER_EPOCH = (2 * SL_TRAIN_SIZE) // BATCH_SIZE + 1\n",
    "VALIDATION_STEPS_PER_EPOCH = (2 * SL_VALIDATION_SIZE) // BATCH_SIZE + 1\n",
    "\n",
    "TRAIN_PATH = \"./data_set/train/\"\n",
    "VALIDATION_PATH = \"./data_set/validation/\"\n",
    "TEST_PATH = \"./data_set/test/\"\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_1_model.json\"\n",
    "WEIGHTS_PATH = \"./binary_classifier/net_1_weights.h5\"\n",
    "\n",
    "rand.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "test_set = []\n",
    "lst = os.listdir(TEST_PATH + 'sea_lions')\n",
    "for elem in lst:\n",
    "    test_set.append(list((cv2.imread(TEST_PATH + 'sea_lions/' + elem), 'sea_lion')))\n",
    "lst = os.listdir(TEST_PATH + 'background')\n",
    "for elem in lst:\n",
    "    test_set.append(list((cv2.imread(TEST_PATH + 'background/' + elem), 'background')))\n",
    "rand.shuffle(test_set)\n",
    "for data in test_set:\n",
    "    X_test.append(data[0])\n",
    "    if data[1] == 'sea_lion':\n",
    "        Y_test.append([1, 0])\n",
    "    else:\n",
    "        Y_test.append([0, 1])\n",
    "X_test = np.array(X_test, copy=False)\n",
    "Y_test = np.array(Y_test, copy=False)\n",
    "\n",
    "# Free memory\n",
    "lst = []\n",
    "test_set = []\n",
    "\n",
    "# Convert data types and normalize values\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parallel model (multi gpu)\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test (multi gpu)\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss_and_metrics = parallel_model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (parallel_model.metrics_names[1], loss_and_metrics[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ROC and AUC\n",
    "\n",
    "Y_pred = parallel_model.predict(X_test)\n",
    "roc_auc_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wrong predicted patches\n",
    "\n",
    "lst = []\n",
    "wrong_lst = []\n",
    "tmp = os.listdir(TEST_PATH + 'sea_lions')\n",
    "for elem in tmp:\n",
    "    lst.append(list((TEST_PATH + 'sea_lions/' + elem, 'sea_lion')))\n",
    "tmp = rand.sample(os.listdir(TEST_PATH + 'background'), SL_TEST_SIZE)\n",
    "for elem in tmp:\n",
    "    test_set.append(list((TEST_PATH + 'background/' + elem, 'background')))\n",
    "for elem in lst:\n",
    "    img = cv2.imread(elem[0])\n",
    "    img.astype('float32')\n",
    "    img /= 255\n",
    "    if elem[1] == 'sea_lion':\n",
    "        expected_class = [1, 0]\n",
    "    else:\n",
    "        expected_class = [0, 1]\n",
    "    prediction = parallel_model.predict(np.array(list(img)))\n",
    "    if prediction[0][0] > prediction[0][1]:\n",
    "        predicted_class = [1, 0]\n",
    "    else:\n",
    "        predicted_class = [0, 1]\n",
    "    if not(expected_class == predicted_class):\n",
    "        wrong_lst.append(list((elem[0], elem[1], prediction[0][0], prediction[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prediction_df = pd.DataFrame(data=wrong_lst, columns=[\"image_path\", \"expected_class\", \"sl_probability\", \"bkg_probability\"])\n",
    "wrong_prediction_df.to_csv(\"./wrong_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
