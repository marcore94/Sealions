{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vincenzo\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from skimage.transform import rotate, resize, SimilarityTransform, warp\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define in advance constants to build the model\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "IM_HEIGHT = 96\n",
    "IM_WIDTH = 96\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIMIZER = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "SL_TRAIN_SIZE = 50121\n",
    "SL_VALIDATION_SIZE = 12531\n",
    "SL_TEST_SIZE = 17634\n",
    "BKG_TEST_SIZE = 328381\n",
    "EPOCHS = 40\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "STEPS_PER_EPOCH = (2 * SL_TRAIN_SIZE) // BATCH_SIZE + 1\n",
    "VALIDATION_STEPS_PER_EPOCH = (2 * SL_VALIDATION_SIZE) // BATCH_SIZE + 1\n",
    "TEST_STEPS = (SL_TEST_SIZE + BKG_TEST_SIZE) // BATCH_SIZE + 1\n",
    "\n",
    "TRAIN_PATH = \"./data_set/train/\"\n",
    "VALIDATION_PATH = \"./data_set/validation/\"\n",
    "TEST_PATH = \"./data_set/test/\"\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_1_model.json\"\n",
    "WEIGHTS_PATH = \"./binary_classifier/net_1_weights.h5\"\n",
    "\n",
    "rand.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(batch_size):\n",
    "    test_set = []\n",
    "    lst = os.listdir(TEST_PATH + 'sea_lions')\n",
    "    for elem in lst:\n",
    "        test_set.append(list((elem, 'sea_lion')))\n",
    "    lst = os.listdir(TEST_PATH + 'background')\n",
    "    for elem in lst:\n",
    "        test_set.append(list((elem, 'background')))\n",
    "    rand.shuffle(test_set)\n",
    "    curr_batch_size = 0\n",
    "    patches = []\n",
    "    classes = []\n",
    "    for elem in test_set:\n",
    "        if elem[1] == 'background':\n",
    "            patches.append(cv2.imread(TEST_PATH + 'background/' + elem[0]))\n",
    "            classes.append([0, 1])\n",
    "        else:\n",
    "            patches.append(cv2.imread(TEST_PATH + 'sea_lions/' + elem[0]))\n",
    "            classes.append([1, 0])\n",
    "        curr_batch_size += 1\n",
    "        if curr_batch_size == batch_size:\n",
    "            X_test = np.array(patches)\n",
    "            X_test = X_test.astype('float32')\n",
    "            X_test /= 255\n",
    "            Y_test = np.array(classes)\n",
    "            patches = []\n",
    "            classes = []\n",
    "            yield X_test, Y_test\n",
    "    if len(patches) > 0:\n",
    "        X_test = np.array(patches)\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_test /= 255\n",
    "        Y_test = np.array(classes)\n",
    "        yield X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator(batch_size, steps):\n",
    "    test_gen = test_generator(batch_size)\n",
    "    Y_roc = []\n",
    "    while steps > 0:\n",
    "        x, y = next(test_gen)\n",
    "        Y_roc.append(y.tolist())\n",
    "        steps -= 1\n",
    "        yield x\n",
    "    yield np.array(Y_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parallel model (multi gpu)\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "# Load weights\n",
    "parallel_model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "parallel_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test (multi gpu)\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss_and_metrics = parallel_model.evaluate_generator(test_generator(BATCH_SIZE), steps=TEST_STEPS)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (parallel_model.metrics_names[1], loss_and_metrics[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 346015 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 93.82%\n"
     ]
    }
   ],
   "source": [
    "# Test (multi gpu)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Evaluate model on test data through flow_from_directory\n",
    "loss_and_metrics = parallel_model.evaluate_generator(test_datagen.flow_from_directory(\n",
    "    directory=TEST_PATH, \n",
    "    target_size=(IM_HEIGHT, IM_WIDTH),\n",
    "    classes=['sea_lions', 'background'],\n",
    "    batch_size=BATCH_SIZE\n",
    "), steps=TEST_STEPS, workers=8, max_queue_size=50)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (parallel_model.metrics_names[1], loss_and_metrics[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator_ffd(steps):\n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    Y_roc = []\n",
    "    curr_step = 0\n",
    "    for x, y in test_gen.flow_from_directory(directory=TEST_PATH, target_size=(IM_HEIGHT, IM_WIDTH), classes=['sea_lions', 'background'], batch_size=BATCH_SIZE):\n",
    "        if curr_step >= steps:\n",
    "            yield np.array(Y_roc)\n",
    "        Y_roc += y.tolist()\n",
    "        yield x\n",
    "        curr_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 346015 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-655f0228265d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEST_STEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mY_roc_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_roc_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vincenzo\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vincenzo\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unknown format is not supported"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Evaluate ROC and AUC\n",
    "gen = prediction_generator_ffd(TEST_STEPS)\n",
    "Y_pred = parallel_model.predict_generator(gen, steps=TEST_STEPS)\n",
    "Y_roc_true = next(gen)\n",
    "roc_auc_score(Y_roc_true, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wrong predicted patches\n",
    "\n",
    "lst = []\n",
    "wrong_lst = []\n",
    "tmp = os.listdir(TEST_PATH + 'sea_lions')\n",
    "for elem in tmp:\n",
    "    lst.append(list((TEST_PATH + 'sea_lions/' + elem, 'sea_lion')))\n",
    "tmp = rand.sample(os.listdir(TEST_PATH + 'background'), SL_TEST_SIZE)\n",
    "for elem in tmp:\n",
    "    lst.append(list((TEST_PATH + 'background/' + elem, 'background')))\n",
    "for elem in lst:\n",
    "    img = cv2.imread(elem[0])\n",
    "    img.astype('float32')\n",
    "    img /= 255\n",
    "    if elem[1] == 'sea_lion':\n",
    "        expected_class = [1, 0]\n",
    "    else:\n",
    "        expected_class = [0, 1]\n",
    "    prediction = parallel_model.predict(np.array(list(img)))\n",
    "    if prediction[0][0] > prediction[0][1]:\n",
    "        predicted_class = [1, 0]\n",
    "    else:\n",
    "        predicted_class = [0, 1]\n",
    "    if not(expected_class == predicted_class):\n",
    "        wrong_lst.append(list((elem[0], elem[1], prediction[0][0], prediction[0][1])))\n",
    "\n",
    "wrong_prediction_df = pd.DataFrame(data=wrong_lst, columns=[\"image_path\", \"expected_class\", \"sl_probability\", \"bkg_probability\"])\n",
    "wrong_prediction_df.to_csv(\"./wrong_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "wrong_prediction_df = pd.read_csv(\"./wrong_predictions.csv\")\n",
    "for row in wrong_prediction_df.iterrows():\n",
    "    if number == 10:\n",
    "        break\n",
    "    else:\n",
    "        number += 1\n",
    "    image = cv2.imread(row['image_path'])\n",
    "    preds = [row['sl_probability'], row['bkg_probability']]\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure()\n",
    "    order = list(reversed(range(len(preds))))\n",
    "    bar_preds = [pr[2] for pr in preds]\n",
    "    labels = (pr[1] for pr in preds)\n",
    "    plt.barh(order, bar_preds, alpha=0.5)\n",
    "    plt.yticks(order, labels)\n",
    "    plt.xlabel('Probability')\n",
    "    plt.xlim(0, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
