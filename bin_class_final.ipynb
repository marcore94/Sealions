{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from skimage.transform import rotate, resize, SimilarityTransform, warp\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (96, 96, 3)\n",
    "IM_HEIGHT = 96\n",
    "IM_WIDTH = 96\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIMIZER = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "SL_TRAIN_SIZE = 40411\n",
    "SL_VALIDATION_SIZE = 9668\n",
    "SL_TEST_SIZE = 13539\n",
    "EPOCHS = 30\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "STEPS_PER_EPOCH = (2 * SL_TRAIN_SIZE) // BATCH_SIZE + 1\n",
    "VALIDATION_STEPS_PER_EPOCH = (2 * SL_VALIDATION_SIZE) // BATCH_SIZE + 1\n",
    "MAX_EPOCHS_WITH_SAME_DATA_SET = 20\n",
    "\n",
    "TRAIN_PATH = \"./data_set/train/\"\n",
    "VALIDATION_PATH = \"./data_set/validation/\"\n",
    "TEST_PATH = \"./data_set/test/\"\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_2_model.h5\"\n",
    "\n",
    "MR_CKPT_PATH = \"./binary_classifier/net_2_most_recent_checkpoint.hdf5\"\n",
    "CB_CKPT_PATH = \"./binary_classifier/net_2_current_best_checkpoint.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=360,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#TODO riscrivere gestione lista immagini\n",
    "def train_generator():\n",
    "    sl_lst_tmp = os.listdir(TRAIN_PATH + '0_sea_lions')\n",
    "    bkg_lst_tmp = os.listdir(TRAIN_PATH + '1_background')\n",
    "    while True:\n",
    "        img_lst = []\n",
    "        for elem in sl_lst_tmp:\n",
    "            img = cv2.imread(TRAIN_PATH + '0_sea_lions/' + elem)\n",
    "            img_lst.append(img[72-48:72+48, 72-48:72+48, :])\n",
    "        for elem in rand.sample(bkg_lst_tmp, SL_TRAIN_SIZE):\n",
    "            img = cv2.imread(TRAIN_PATH + '1_background/' + elem)\n",
    "            img_lst.append(img)\n",
    "        X_train = np.array(img_lst, copy=False).astype('float32')\n",
    "        Y_train = np.array([[1, 0]]*SL_TRAIN_SIZE + [[0, 1]]*SL_TRAIN_SIZE)\n",
    "        for i in range(MAX_EPOCHS_WITH_SAME_DATA_SET):\n",
    "            j = 0\n",
    "            for batch in train_datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE):\n",
    "                if j == STEPS_PER_EPOCH:\n",
    "                    break\n",
    "                yield batch\n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    # trasformazioni da implementare rotate, flip, shift, zoom\n",
    "    sel = [0, 1]\n",
    "    offset = 72\n",
    "    bound = (72 - 48) / 2\n",
    "    t_img = np.array(img)\n",
    "    if rand.choice(sel):\n",
    "        # rotate\n",
    "        angle = rand.uniform(0, 360)\n",
    "        t_img = rotate(t_img, angle, mode='edge')\n",
    "    if rand.choice(sel):\n",
    "        # flip\n",
    "        if rand.choice(sel):\n",
    "            t_img = np.flipud(t_img)\n",
    "        if rand.choice(sel):\n",
    "            t_img = np.fliplr(t_img)\n",
    "    if rand.choice(sel):\n",
    "        # shift\n",
    "        tform = SimilarityTransform(translation=(int(rand.uniform(-bound, bound)), int(rand.uniform(-bound, bound))))\n",
    "        t_img = warp(t_img, tform)\n",
    "    if rand.choice(sel):\n",
    "        # zoom\n",
    "        zoom = int(rand.uniform(-bound, bound))\n",
    "        t_img = resize(t_img[offset-48-zoom:offset+48+zoom, offset-48-zoom:offset+48+zoom, :], (96, 96))\n",
    "        return t_img.tolist()\n",
    "    # Cut 96x96 patch\n",
    "    t_img = t_img[offset-48:offset+48, offset-48:offset+48, :]\n",
    "    return t_img.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    sl_lst_tmp = os.listdir(TRAIN_PATH + '0_sea_lions')\n",
    "    sl_lst = []\n",
    "    for elem in sl_lst_tmp:\n",
    "        sl_lst.append(list((cv2.imread(TRAIN_PATH + '0_sea_lions/' + elem), 'sea_lion')))\n",
    "    bkg_lst_tmp = os.listdir(TRAIN_PATH + '1_background')\n",
    "    while True:\n",
    "        img_lst = []\n",
    "        for elem in rand.sample(bkg_lst_tmp, SL_TRAIN_SIZE):\n",
    "            img_lst.append(list((cv2.imread(TRAIN_PATH + '1_sea_lions/' + elem), 'background')))\n",
    "        img_lst = sl_lst + img_lst\n",
    "        rand.shuffle(img_lst)\n",
    "        for i in range(MAX_EPOCHS_WITH_SAME_DATA_SET):\n",
    "            patches = []\n",
    "            classes = []\n",
    "            curr_batch_size = 0\n",
    "            for elem in img_lst:\n",
    "                if elem[1] == 'background':\n",
    "                    patches.append(elem[0])\n",
    "                    classes.append([0, 1])\n",
    "                else:\n",
    "                    patches.append(copy.copy(elem[0]))\n",
    "                    classes.append([1, 0])\n",
    "                curr_batch_size += 1\n",
    "                if curr_batch_size == batch_size:\n",
    "                    X_train = np.array(patches)\n",
    "                    X_train = X_train.astype('float32')\n",
    "                    X_train /= 255\n",
    "                    Y_train = np.array(classes)\n",
    "                    curr_batch_size = 0\n",
    "                    patches = []\n",
    "                    classes = []\n",
    "                    yield X_train, Y_train\n",
    "            if len(patches) > 0:\n",
    "                X_train = np.array(patches)\n",
    "                X_train = X_train.astype('float32')\n",
    "                X_train /= 255\n",
    "                Y_train = np.array(classes)\n",
    "                yield X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data set\n",
    "X_validation = []\n",
    "Y_validation = []\n",
    "validation_set = []\n",
    "lst = os.listdir(VALIDATION_PATH + '0_sea_lions')\n",
    "for elem in lst:\n",
    "    validation_set.append(list((cv2.imread(VALIDATION_PATH + '0_sea_lions/' + elem), 'sea_lion')))\n",
    "lst = os.listdir(VALIDATION_PATH + '1_background')\n",
    "for elem in lst:\n",
    "    validation_set.append(list((cv2.imread(VALIDATION_PATH + '1_background/' + elem), 'background')))\n",
    "rand.shuffle(validation_set)\n",
    "for data in validation_set:\n",
    "    X_validation.append(data[0])\n",
    "    if data[1] == 'sea_lion':\n",
    "        Y_validation.append([1, 0])\n",
    "    else:\n",
    "        Y_validation.append([0, 1])\n",
    "\n",
    "X_validation = np.array(X_validation, copy=False)\n",
    "# Convert data types and normalize values\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_validation /= 255\n",
    "Y_validation = np.array(Y_validation, copy=False)\n",
    "\n",
    "# Free memory\n",
    "lst = []\n",
    "validation_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointers\n",
    "\n",
    "# most recent checkpoint\n",
    "mr_checkpointer = ModelCheckpoint(filepath=MR_CKPT_PATH, verbose=1, save_best_only=False)\n",
    "# current best checkpoint\n",
    "cb_checkpointer = ModelCheckpoint(filepath=CB_CKPT_PATH, verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "# Fit model on training data\n",
    "history = model.fit_generator(\n",
    "    train_generator(),\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validation, Y_validation),\n",
    "    validation_steps=VALIDATION_STEPS_PER_EPOCH,\n",
    "    workers=8,\n",
    "    max_queue_size=50,\n",
    "    callbacks=[mr_checkpointer, cb_checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "\n",
    "# serialize model to HDF5\n",
    "model.save(MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
