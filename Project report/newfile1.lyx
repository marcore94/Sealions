#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command makeindex
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\begin_layout Plain Layout

	
\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename polimi.png
	lyxscale 10
	width 4cm

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

	{
\backslash
scshape
\backslash
LARGE Politecnico di Milano 
\backslash
par}
\end_layout

\begin_layout Plain Layout

	
\backslash
vspace{1cm}
\end_layout

\begin_layout Plain Layout

	{
\backslash
scshape
\backslash
Large Image Analysis and Computer Vision
\backslash
par}
\end_layout

\begin_layout Plain Layout

	
\backslash
vspace{1.5cm}
\end_layout

\begin_layout Plain Layout

	{
\backslash
huge
\backslash
bfseries Project Report 
\backslash
par}
\end_layout

\begin_layout Plain Layout

	
\backslash
vfill 	Course teacher
\backslash
par	Professor	Vincenzo 
\backslash
textsc{Caglioti}
\end_layout

\begin_layout Plain Layout

	
\backslash
vfill 	Project supervisors
\backslash
par	Professor	Giacomo 
\backslash
textsc{Boracchi}
\backslash
par	Professor	Diego 
\backslash
textsc{Carrera}
\end_layout

\begin_layout Plain Layout

	
\backslash
end{center}
\end_layout

\begin_layout Plain Layout

	
\backslash
vfill
\end_layout

\begin_layout Plain Layout

	
\backslash
begin{tabular}{r}
\end_layout

\begin_layout Plain Layout

	{
\backslash
small
\backslash
itshape Perugini Alex 876359 
\backslash
par}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

	{
\backslash
small
\backslash
itshape Re Marco 873564 
\backslash
par}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

	{
\backslash
small
\backslash
itshape Scotti Vincenzo 875505 
\backslash
par}
\end_layout

\begin_layout Plain Layout

	
\backslash
end{tabular} 
\backslash
hfill
\end_layout

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter
Problem formulation
\end_layout

\begin_layout Standard
The proposed project consisted in the implementation of a convolutional
 neural network for the classification of sea lions using pictures extracted
 from aerial images.
\begin_inset Newline newline
\end_inset

The idea of the project is based on a Kaggle competition featured in 2017
 (
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count
\end_layout

\end_inset

) where the objective was to provide a sea lions population count using
 fully convolutional neural network to analyze the aerial images taken by
 drones.
 Moreover it was required also to distinguish five classes among sea lions
 based on age and sex: 
\end_layout

\begin_layout Itemize
adult male
\end_layout

\begin_layout Itemize
adult female
\end_layout

\begin_layout Itemize
subadult male
\end_layout

\begin_layout Itemize
juvenile
\end_layout

\begin_layout Itemize
puppy 
\end_layout

\begin_layout Standard
The original aim of this competition was to automatize work done by biologist
 to keep track of the sea lions population.
 This manual work takes up to four months to count sea lions from those
 images.
 Due to this long time needed, automatizing this work would allow biologist
 to focus more on sea lions problems, rather on this counting task.
\begin_inset Newline newline
\end_inset

The requirement assigned to our group for the project was to provide a classifie
r that was able to distinguish only 2 classes:
\end_layout

\begin_layout Itemize
sea lion
\end_layout

\begin_layout Itemize
background
\end_layout

\begin_layout Standard
without any distinction between the sea lions subclasses.
\begin_inset Newline newline
\end_inset

To accomplish to the task we used the dataset provided by kaggle that included,
 for each image, the ground truth expressed as a point centered on each
 sea lion with different colors for the different classes.
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 0.jpg
	lyxscale 1
	scale 6
	BoundingBox 0bp 0bp 5616bp 3744bp
	clip
	rotateOrigin centerBottom

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Sample image from the dataset
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter
State of the art
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Image classification is a fundamental problem in computer vision since it
 forms the basis for other computer vision tasks such as localization, detection
, and segmentation
\begin_inset CommandInset citation
LatexCommand cite
key "key-4"
literal "false"

\end_inset

.
 Although the task can be considered second nature for humans, it is much
 more challenging for an automated system.
\begin_inset Newline newline
\end_inset

Traditionally handcrafted features were first extracted from images using
 feature descriptors, and these served as input to a trainable classifier,
 in this way the accuracy of the classification task was profoundly dependent
 on the design of the feature extraction stage, and this usually proved
 to be a difficult task that required domain experts
\begin_inset CommandInset citation
LatexCommand cite
key "key-7"
literal "false"

\end_inset

.
 In recent years, deep learning models that exploit multiple layers of nonlinear
 information processing, for feature extraction and transformation as well
 as for pattern analysis and classification, have been shown to overcome
 these challenges.
 Among them, CNNs have become the leading architecture for most image recognitio
n, classification, and detection tasks
\begin_inset CommandInset citation
LatexCommand cite
key "key-8,key-9,key-10"
literal "false"

\end_inset

.
\end_layout

\begin_layout Section
Convolutional Neural Networks
\end_layout

\begin_layout Standard
CNNs are feedforward networks in that information flow takes place in one
 direction only, from their inputs to their outputs.
 Just as artificial neural networks (ANN) are biologically inspired, so
 are CNNs.
 The visual cortex in the brain, which consists of alternating layers of
 simple and complex cells, motivates their architecture 
\begin_inset CommandInset citation
LatexCommand cite
key "key-5,key-6"
literal "false"

\end_inset

.
 CNN architectures come in several variations, however, in general, they
 consist of convolutional and pooling (or subsampling) layers, which are
 grouped into modules.
 Either one or more fully connected layers, as in a standard feedforward
 neural network, follow these modules.
 Modules are often stacked on top of each other to form a deep model.
\begin_inset Newline newline
\end_inset

Despite some early sucesses
\begin_inset CommandInset citation
LatexCommand cite
key "key-8,key-9,key-11"
literal "false"

\end_inset

, deep CNN were brought into the limelight as a result of the deep learning
 reanaissance
\begin_inset CommandInset citation
LatexCommand cite
key "key-12,key-13,key-14"
literal "false"

\end_inset

, which was fueled by GPUs, larger data sets and better algorithms
\begin_inset CommandInset citation
LatexCommand cite
key "key-19,key-20,key-21"
literal "false"

\end_inset

.
 Several advances such as GPU implementations and the application of maximum
 pooling have contributed to the recent popularity.
\begin_inset Newline newline
\end_inset

The most significant advance, which has captured intense interest in DCNNs,
 especially for image classification tasks, was achieved in the ImageNet
 Large Scale Visual Recognition Challenge (ILSVRC) 2012
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"
literal "false"

\end_inset

.
 Since then, DCNNs have dominated subsequent versions of the ILSVRC and,
 more specifically, its image classification component
\begin_inset CommandInset citation
LatexCommand cite
key "key-3,key-21,key-22"
literal "false"

\end_inset

.
 In addition to these advances other improvements affected the performances
 of DCNN such as non linear activation functions
\begin_inset CommandInset citation
LatexCommand cite
key "key-23,key-24"
literal "false"

\end_inset

, regularization mechanisms 
\begin_inset CommandInset citation
LatexCommand cite
key "key-25,key-26"
literal "false"

\end_inset

 and optimization techniques
\begin_inset CommandInset citation
LatexCommand cite
key "key-27,key-19"
literal "false"

\end_inset

.
\begin_inset Newline newline
\end_inset

Nowadays convolutional networks are driving the advances in recognition,
 in fact convnets are not only improving whole-image classification tasks
\begin_inset CommandInset citation
LatexCommand cite
key "key-19,key-22,key-3"
literal "false"

\end_inset

, but also local tasks with structured output such as bounding box object
 detection
\begin_inset CommandInset citation
LatexCommand cite
key "key-30,key-29,key-23"
literal "false"

\end_inset

, part and keypoint prediction 
\begin_inset CommandInset citation
LatexCommand cite
key "key-33,key-32"
literal "false"

\end_inset

 and local correspondence
\begin_inset CommandInset citation
LatexCommand cite
key "key-32,key-31"
literal "false"

\end_inset

.
\end_layout

\begin_layout Section
Fully convolutional networks
\end_layout

\begin_layout Standard
Due to the astonishing results in the aforementioned topics, the natural
 next step in the progression from coarse to fine inference yield to pixelwise
 prediction.
 A prior approach used convnets for semantic segmentation
\begin_inset CommandInset citation
LatexCommand cite
key "key-34,key-35,key-36,key-37,key-38,key-39,key-40"
literal "false"

\end_inset

, however, for training, this required that in the ground truth each pixel
 was labeled with the class of its enclosing object or region in the ground.
\begin_inset Newline newline
\end_inset

An important advance in this sense was introduced by fully convolutional
 neural networks
\begin_inset CommandInset citation
LatexCommand cite
key "key-41"
literal "false"

\end_inset

: the key idea was to extend convnets to arbitrary-sized inputs by model
 transfer.
 Differently from previous approaches that was based on sliding windows
 
\begin_inset CommandInset citation
LatexCommand cite
key "key-29"
literal "false"

\end_inset

, separately computed feature extractors 
\begin_inset CommandInset citation
LatexCommand cite
key "key-23"
literal "false"

\end_inset

 or Recurrent CNN
\begin_inset CommandInset citation
LatexCommand cite
key "key-42"
literal "false"

\end_inset

, FCNN exploit end-to-end supervised pre-training for pixelwise prediction
 
\begin_inset CommandInset citation
LatexCommand cite
key "key-41,key-43"
literal "false"

\end_inset

.
\begin_inset Newline newline
\end_inset

Typical recognition nets were realized to take fixed-size inputs and produce
 non spatial outputs
\begin_inset CommandInset citation
LatexCommand cite
key "key-3,key-21,key-22"
literal "false"

\end_inset

, the fully connected layers of these networks had fixed dimensions and
 threw away spatial coordinates.
 These fully connected layers can also be viewed as convolutions with kernels
 that cover the entire input regions, doing so it's possible to cast them
 into fully convolutional networks that take inputs of any size and give
 as outputs the classification maps
\begin_inset CommandInset citation
LatexCommand cite
key "key-41"
literal "false"

\end_inset

.
\begin_inset Newline newline
\end_inset

Since the classification nets subsample to keep filters small and computational
 requirements reasonable, the output of a fully convolutional version of
 these nets results coarsen, reducing it from the size of the input by a
 factor equal to the pixel stride of the receptive fields of the output
 units.
 To cope with this problem and connect coarse outputs to dense pixels interpolat
ion by upsampling can be adopted.
 Upsampling can be implemented by deconvolution and learned by backpropagation
 of the pixelwise loss
\begin_inset CommandInset citation
LatexCommand cite
key "key-41"
literal "false"

\end_inset

.
\end_layout

\begin_layout Chapter
Solution Approach
\end_layout

\begin_layout Standard
Images in the provided dataset were taken from drones, thus they are very
 large and contains a lot of sea lions and different background areas.
 Due to the impossibility of using the whole images to train the network,
 the first step was to create a suitable training dataset.
 To do this, we extracted patches from the provided dataset and trained
 a binary classifier on patches.
\begin_inset Newline newline
\end_inset

After having extracted them, we decided to apply data augmentation to obtain
 a more robust classifier.
 This allowed us to increase a lot the dimension of the original dataset,
 in particular for what concerns sea lions patches.
 In fact, due to the nature of the images, they contained much more background
 patches than sea lions ones.
 By data augmentation we were able to overcome, partially, this unbalance
 and to obtain better performance during testing phase becaute it makes
 the classifier more insensitive to position, rotation and scaling.
\begin_inset Newline newline
\end_inset

Once performances over patches were satisfying, we moved to an higher level,
 modifying the network to take as input the whole image and providing an
 heatmap of it.
 This gives the possibility, given an image, to see where and how sea lions
 are distributed in the environment and to compute an estimate of how many
 sea lions are present in that image.
 
\end_layout

\begin_layout Chapter
Implementation
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Dataset-creation"

\end_inset

Dataset creation
\end_layout

\begin_layout Standard
The first thing to do with images provided by Kaggle is to divide them in
 train and test set, in particular the first 
\begin_inset Formula $750$
\end_inset

 images were used for training and the remaining ones (from 
\begin_inset Formula $751$
\end_inset

 to 
\begin_inset Formula $947$
\end_inset

) for testing.
\begin_inset Newline newline
\end_inset

The extraction of patches from Kaggle images has been done performing the
 absolute difference between the original image and its corresponding one
 with colored dots on the sea lions, in this way it’s possible to gather
 from each image coordinates and class of all the sea lions.
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Schermata 2018-05-12 alle 19.08.01.png
	lyxscale 10
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Original image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Schermata 2018-05-12 alle 19.08.59.png
	lyxscale 10
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Dotted image
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of train and train-dotted images provided by kaggle
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Given these coordinates it’s easy to cut from the original images a 
\begin_inset Formula $96\times96$
\end_inset

 area around them and save the patches labeling them as ‘sea lion’.
\begin_inset Newline newline
\end_inset

To extract the background we used a sliding window of size 
\begin_inset Formula $96\times96$
\end_inset

 over the image and cut all the patches which were not intersecting with
 a sea lion patch and save them with label ‘background’.
 
\end_layout

\begin_layout Standard
The train set at the end of the extraction procedure includes 
\begin_inset Formula $50079$
\end_inset

 ‘sea lions’ and 
\begin_inset Formula $1139531$
\end_inset

 ‘background’ patches which will be split again in 
\begin_inset Formula $40411$
\end_inset

, 
\begin_inset Formula $9668$
\end_inset

 and 
\begin_inset Formula $1129863$
\end_inset

, 
\begin_inset Formula $9668$
\end_inset

 respectively for proper train and validation procedures.
 The test set instead has 
\begin_inset Formula $13539$
\end_inset

 ‘sea lions’ and 
\begin_inset Formula $277390$
\end_inset

 ‘background’ patches.
 Given this dataset divided into classes, train, validation and test set
 it’s possible to train the model.
 
\begin_inset Newline newline
\end_inset

Going deep in the training and testing procedures we noticed some important
 problems with the dataset: 
\end_layout

\begin_layout Itemize
mismatches in the ground truth provided by kaggle, we listed and removed
 all these images
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename mismatch-a_21.jpg
	lyxscale 2
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Original image '21'
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename mismatch-b_21.jpg
	lyxscale 2
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ground truth image '21'
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of mismatch between original image and ground truth provided by
 kaggle
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
blob detection technique provided some false positives that ended up labled
 in the wrong way, so we also inspected manually the patches to cope with
 this problem
\end_layout

\begin_layout Itemize
some images have areas covered with black color so we added a check to discard
 all patches with more than 2% of pure black color, in this way the sliding
 window gathering the background excludes black patches
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename black-sample-a_22.jpg
	lyxscale 2
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ground truth image '22'
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename black-sample-b_26.jpg
	lyxscale 2
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ground truth image '26'
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of two images covered with black areas
\end_layout

\end_inset


\end_layout

\end_inset

As can be seen from these two images avoiding balck patches is fundamental
 to have a correct dataset.
\end_layout

\begin_layout Standard
Once the extraction procedure has been fully completed and all its related
 problems have been solved, we detectde new problems related to the patches
 themselves.
 In fact the two classes are really unbalanced, there are a lot more background
 patches than sea lion ones, furthermore 
\begin_inset Formula $40411$
\end_inset

 sea lion patches might not be sufficient to learn that class correctly
 without overfitting.
\end_layout

\begin_layout Section
Data augmentation
\end_layout

\begin_layout Standard
As explained before, to increase the dimension of the dataset and generalize
 more over position, rotation and scale we applied data augmentation to
 the sea lions patches.
 This technique has been applied to solve the problems related to the dataset
 that came up after patches extraction 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Dataset-creation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, in fact it allows to expand the dataset creating new patches modifying
 the extracted ones, this is fundamental especially due to the poorness
 that characterize the sea lion class.
 Moreover, training a model with augmented patches makes it more robust
 and consistent in classifying previously unseen samples.
 In particular, what we applied is a random combination of four transformation:
\end_layout

\begin_layout Itemize
Rotation of a random degree in the range 
\begin_inset Formula $0$
\end_inset

 to 
\begin_inset Formula $360$
\end_inset

 degrees
\end_layout

\begin_layout Itemize
Flipping both vertically and horizontally
\end_layout

\begin_layout Itemize
Shifting of a maximum of 
\begin_inset Formula $10$
\end_inset

 pixels, both vertically and horizontally
\end_layout

\begin_layout Itemize
Zooming of a maximum of 
\begin_inset Formula $20$
\end_inset

 pixels
\end_layout

\begin_layout Standard
The transformation process is, as said before, completely random so the
 nuber of new patches that can be generated is really high, that's why with
 these transformations is possible to overcome the problem of lack of sea
 lion patches and class unbalance.
\end_layout

\begin_layout Standard
The first implementation we tried for the augmentation procedure was to
 build our own handcrafted tool which behaved exactly as described before.
 This tool was built to receive as input higher size sea lion patches (
\begin_inset Formula $144\times144$
\end_inset

) to avoid interpolation of eventual missing pixels due to the transformations
 and have a final transformed patch as much precise as possible.
 Of course patches must be modified at runtime, during the network training,
 because it's impossible to save all the patches that can be generated with
 augmentation.
 At this point we noticed that the tool we built was not as fast as we expected
 so we decided to replace it with the Keras built-in data generator which
 allows to apply augmentation.
 Data generator provided by Keras doesn't require bigger patches as input
 beacuse automatically applies interpolation to fill eventual missing pixels
 and mantain sizes of the input image.
 With this augmentation tool the process of loading modified patches at
 runtime speeded up consistently so the whole train process became less
 time consuming.
\end_layout

\begin_layout Standard
Here follows samples of modified patches
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/original.png
	lyxscale 10
	width 60col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Original image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_0.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_1.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_2.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_3.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_4.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Augmentation/Augmentation_6.png
	lyxscale 10
	width 33col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Augmented image
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Augmentation samples
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Model
\end_layout

\begin_layout Standard
The DCNN used to classify patches has input size of 
\begin_inset Formula $96\times96\times3$
\end_inset

 and output size of 
\begin_inset Formula $2$
\end_inset

, where each output corresponds to the probability of belonging to a class.
 The network is made up of 
\begin_inset Formula $9$
\end_inset

 layers
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename CNNDiagram.pdf
	lyxscale 10
	scale 90
	rotateOrigin center

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
CNN model
\end_layout

\end_inset


\end_layout

\end_inset

Other characteristics of the model are:
\end_layout

\begin_layout Itemize
optimizer: Adam, a stochastic optimization method which uses gradients and
 second moment gradients to perform parameter update 
\end_layout

\begin_layout Itemize
loss function: binary cross entropy, error function based on class probabilities
\end_layout

\begin_layout Itemize
metric: accuracy, evaluation of the model based on how much the classification
 is accurate
\end_layout

\begin_layout Section
Semantic segmentation
\end_layout

\begin_layout Standard
As soon as the CNN building and training phases ended we proceeded to extract
 the fully convolutional model.
 To do so we reshaped the fully connected final layer to another convolutional
 layer maintaining the same connections and related weights of the original
 network, the new final convolutional layer used 
\begin_inset Formula $2$
\end_inset

 filters (one for each label) and a 
\begin_inset Formula $4\times4$
\end_inset

 kernel, with a softmax activation function.
\begin_inset Newline newline
\end_inset

Since we dropped the constraints on the input shape it was possible to feed
 an entire image to the network that produced as output two heatmaps that
 highlighted respectively the pixels belonging to the sea lion and the backgroun
d classes according to the probabilities predicted by the classifier.
\begin_inset Newline newline
\end_inset

It is important to stress out that we didn’t use any shift-and-stitch or
 upsampling via deconvolution to yield the dense predictions, instead we
 applied a simple interpolation to the results.
 
\end_layout

\begin_layout Chapter
Experimental activity and results
\end_layout

\begin_layout Section
Developement tools
\end_layout

\begin_layout Standard
In order to perform the tasks required by the project we used jupyter notebooks
 that allowed to write python code and to execute it section by section,
 in this way we were able to monitor the results as soon as each step was
 completed.
\begin_inset Newline newline
\end_inset

Thanks to the choice of python we managed to use Keras, an high-level neural
 networks API, with the TensorFlow framework as backend.
 The choice of Keras helped to simplify the development while TensorFlow
 allowed us to take advantage of GPU acceleration that sped up the entire
 training process significantly.
\begin_inset Newline newline
\end_inset

Another aspect that characterized the development was the use of dataframes
 that allowed a better management of all the informations about the data
 set.
\end_layout

\begin_layout Section
First training
\end_layout

\begin_layout Standard
As can be seen from the number of extracted patches the dataset is unbalanced,
 there are a lot more background patches than sea lion ones, but the first
 training was meant to be as simple as possible so balanced train and test
 set were created performing random sampling from background and augmentation
 technique was not applied.
 This simplified a lot the first training of the network and produced very
 good results.
\begin_inset Newline newline
\end_inset

For what concerns the training procedure, we ran it for 100 epochs using
 a learning rate of 
\begin_inset Formula $0.001$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename binary_classifier_ra_8_0.png
	lyxscale 10
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model accuracy
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename binary_classifier_ra_8_1.png
	lyxscale 10
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model loss
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Loss and accuracy history
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

To measure performances we considered not only the accuracy, but also the
 area under the curve (
\begin_inset Formula $AUC$
\end_inset

) of the receiver operating characteristic (
\begin_inset Formula $ROC$
\end_inset

) curve.
 Up to this point, we achieved an 
\begin_inset Formula $AUC$
\end_inset

 of 
\begin_inset Formula $99.29\%$
\end_inset

.
 Here follows more detailed tables about the results.
\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Loss$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Accuracy$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Train set
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.0768$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9733$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Validation set
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.0891$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9679$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
End of training performances
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prediction accuracy
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $96.60\%$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $AUC$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9929$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Testing results
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
First training results
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Second training
\end_layout

\begin_layout Standard
After that, we decided to use the whole dataset both for training and testing
 rather than a balanced one because the real problem is to identify sea
 lions among a lot of background.
 This caused different problems, in particular due to memory usage and to
 high number of background patches with respect to sea lions ones.
\begin_inset Newline newline
\end_inset

Memory related problems were linked to the fact that training dataset was
 of some Gigabytes, thus it couldn’t fit all in the memory at the same time.
 To overcome this we created a batch generator which retrieved a limited
 number of patches from the memory and fed them to the network at each epoch.
 In this way only a little amount of patches were moved into the RAM at
 the same time.
 After they were used by the network, they were flushed.
\begin_inset Newline newline
\end_inset

This generator also enabled us to introduce data augmentation in the training
 step.
 As stated in the previous sections, it was needed due to the high difference
 in number between sea lions and background patches and also to obtain more
 robust results in classification, in fact with this technique it’s more
 likely to be rotation and scale invariant.
\begin_inset Newline newline
\end_inset

In this first attempt to add augmentation we used an handcrafted tool to
 apply the transformations, to do this we had to work with higher size sea
 lions patches that were cropped after the transformation to fit the network
 input.
 In this way we could avoid interpolation on eventual missing pixels that
 was necessary with Keras built-in functions since we applied the transformation
s at runtime.
\begin_inset Newline newline
\end_inset

To train the network we decided to create a balanced data set composed of
 all the sea lions patches with augmentation and an equal number of background
 patches random sampled from all the background patches.
 This dataset is used for one epoch and then changed, creating a new one
 with the same criteria.
 In this way the network sees all the sea lions patches different times
 but overfitting is prevented by the wide amount of modifications introduced
 by the augmentation.
 While the background patches are used in an efficient way because network
 sees a wide variety of them while keeping the procedure memory efficient.
\begin_inset Newline newline
\end_inset

Although these premises, results were not good and the network very bad,
 being not so better with respect to a random classifier.
\begin_inset Newline newline
\end_inset

This training allowed us to identify three new problems: changing the dataset
 at each epoch is time consuming, because loading the patches from disk
 to memory is a bottleneck in the whole procedure, moreover because of the
 handcrafted augmentation tool even the batch creation was slowed down;
 puppies are really hard to be identified by the network, with their color
 and shape can be easily mistaken as background also by human eye.
\begin_inset Newline newline
\end_inset

Given that this training was particularly time consuming for the reasons
 discussed before, the network was trained for only 
\begin_inset Formula $30$
\end_inset

 epochs with a 
\begin_inset Formula $0.0005$
\end_inset

 learning rate.
 The procedure took a lot of time and was not sufficient to learn enough
 from the data provided.
 
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename bin_class_ra_with_augment_8_0.png
	lyxscale 10
	scale 60
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model accuracy
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename bin_class_ra_with_augment_8_1.png
	lyxscale 10
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model loss
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Loss and accuracy history
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename bin_class_ra_with_augmented_testing_8_1.png
	lyxscale 10
	scale 50
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $ROC$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename bin_class_ra_with_augmented_testing_11_1.png
	lyxscale 10
	scale 50
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Precision-recall curve
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $ROC$
\end_inset

 and precision-recall curves
\end_layout

\end_inset


\end_layout

\end_inset

As shown by the following tables the presence of a much higher number of
 background patches influenced a lot the metrics used to estimate the model
 performances, in particular while the accuracy was still close to that
 of the previous training the AUC shows a significant drop and gets close
 to 0.5 (the random classifier limit).
\begin_inset Newline newline
\end_inset

We can also directly compare the accuracy of this training with the previous
 one.
 If we restrict the analysis to the first 30 epochs and on the validation
 set, to have a meaningful comparison, the first training provides an accuracy
 of about 
\begin_inset Formula $96.6\%$
\end_inset

, while this one only of the 
\begin_inset Formula $91.38\%$
\end_inset

.
 Also, the variation of accuracy from the beginning of the training is about
 
\begin_inset Formula $4\%$
\end_inset

, while this one is of less than the 
\begin_inset Formula $2\%$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Loss$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Accuracy$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Train set
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.0533$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9813$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Validation set
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.2689$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9138$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
End of training performances
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prediction accuracy
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $94.91\%$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $AUC$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.5864$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Testing results
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Precision$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Recall$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sea lions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.2948$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.0228$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Background
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9516$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9972$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Precision and recall scores
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Second training results
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Third training
\end_layout

\begin_layout Standard
The purpose of this training was to solve all the problems that came up
 in the previous one.
\begin_inset Newline newline
\end_inset

The first adjustment was to change the dataset and reload it from memory
 every 15 epochs and not at each epoch, this choice speeded up the whole
 training phase allowing us to train for more epochs.
 The problem related to puppies was solved analyzing where and how they
 appear in the images, in fact it can be noticed that this particular class
 is often next to a female sea lion.
\begin_inset Newline newline
\end_inset

Thanks to this information we were able to apply a second important change:
 remove puppies from the dataset.
 In this way for the network it’s easier to learn and distinguish between
 all the other classes of sea lions and the background so it’s possible
 to achieve better performances.
 At the end, in the final result, the number of puppies can be estimated
 from the number of sea lions detected.
\begin_inset Newline newline
\end_inset

Another remarkable difference with respect to the last training was that
 we dropped the handcrafted augmentation tool in favor of Keras built-in
 one that enabled a much higher throughput in the creation of the training
 batches.
\begin_inset Newline newline
\end_inset

Performances of this model were measured again using accuracy, that is 
\begin_inset Formula $97.27\%$
\end_inset

, and 
\begin_inset Formula $AUC$
\end_inset

 of the 
\begin_inset Formula $ROC$
\end_inset

 curve, which is 
\begin_inset Formula $99.64\%$
\end_inset

, plus other metrics such as precision and recall respectively 
\begin_inset Formula $62.53\%$
\end_inset

 and 
\begin_inset Formula $97.68\%$
\end_inset

 over the sea lions.
 
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename metrics_eval_2_0.png
	lyxscale 10
	scale 60
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model accuracy
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename metrics_eval_2_1.png
	lyxscale 10
	scale 60
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model loss
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Loss and accuracy history
\end_layout

\end_inset


\end_layout

\end_inset

During this phase we set the learning rate to 
\begin_inset Formula $0.0005$
\end_inset

 and we trained for 
\begin_inset Formula $60$
\end_inset

 epochs.
\begin_inset Newline newline
\end_inset

The following graphs and tables highlight the enhancements of the new training:
 the ROC nearly covers all the graph area, resulting in a AUC higher than
 first training one, the same applies for the precision-recall curve.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename results_testing_unweighted_6_1.png
	lyxscale 10
	scale 60
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Confusion matrix
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename results_testing_unweighted_4_1.png
	lyxscale 10
	scale 55
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $ROC$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename results_testing_unweighted_7_1.png
	lyxscale 10
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Precision-recall curve
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Confusion matrix, 
\begin_inset Formula $ROC$
\end_inset

 and precision-recall curves
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prediction accuracy
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $97.27\%$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $AUC$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9964$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Testing results
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Precision$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Recall$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sea lions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.6253$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9768$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Background
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9989$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9275$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Precision and recall scores
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Third training results
\end_layout

\end_inset


\end_layout

\end_inset

We also performed some testing in the case of a balanced test set.
 Here are reported the results in this case and we can see that the precision
 in classification of sea lions increases highly with respect to the unbalanced
 test set case.
 On the other hand, there is a slight decrease in the precision of background
 classification.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename results_testing_unweighted_9_1.png
	lyxscale 10
	scale 60
	rotateOrigin center

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Confusion matrix with the balanced test set
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Precision$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Recall$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sea lions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9722$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9768$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Background
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9767$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9721$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Precision and recall scores on a balanced test set
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Semantic segmentation and sea lions counting
\end_layout

\begin_layout Standard
At this point we took the last trained network and, as explained before,
 replaced the last fully connected layer with a convolutional one maintaining
 all the weights.
 With this reshaped network we are able to evaluate an entire image and
 obtain a heatmap highlighting zone where is more probable to have a sea
 lion.
\begin_inset Newline newline
\end_inset

Then we decided to apply a threshold on the heatmap to create a grayscale
 image with white zones corresponding to sea lions.
 On this new image it was possible to apply blob detection, refined through
 parameter tuning as for the heatmap threshold, to have a rough count of
 how many sea lions are present in the considered image.
 The entire procedure is depicted in the following figures.
 As shown the results are quite satisfying even though the blobs don’t always
 overlap correctly with the sea lions.
 
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Detection/Detection_10_0.png
	lyxscale 10
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Original image
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Detection/Detection_11_0.png
	lyxscale 10
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Heatmap
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Detection/Detection_12_0.png
	lyxscale 10
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Blobs
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Detection/Detection_13_0.png
	lyxscale 10
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Detected-sea-lions"

\end_inset

Detected sea lions
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Sea lions detection
\end_layout

\end_inset


\end_layout

\end_inset

Here also follows a comparison of blob counting and true number of sea lions
\begin_inset Newline newline
\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $True$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Predicted$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Image 755
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $212$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $233$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Image 771
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $149$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $141$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Image 773
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $391$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $411$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Image 907
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $93$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $123$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Sea lions counting based on blobs
\end_layout

\end_inset


\end_layout

\end_inset

As can be seen from these numbers, even if the prediction on the nuber of
 sea lions isn't performed with a deeply studied strategy, final results
 aren't too bad.
 In particular, looking at figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Detected-sea-lions"
plural "false"
caps "false"
noprefix "false"

\end_inset

, can be noticed that some animals are not covered by blobs and there are
 some mistaken blobs over the background, therefore we can say this method
 is not the best to count sea lions with high precision due to the presence
 of these errors.
\end_layout

\begin_layout Standard
Another final consideration that can be done is that the predicted number
 is clearly an overestimate of the real one, but the presence of puppies,
 which are not considered in this network, makes the two nubers be closer
 one to each other.
\end_layout

\begin_layout Chapter
Conclusions
\end_layout

\begin_layout Standard
The work done for this project produced a convolutional neural network able
 to achieve good performance on the classification of sea lions over background.
 In particular we want to point out how the two major enhancements we did
 to improve the performance of the network, i.e.
 data augmentation and the management of the dataset during the training,
 have actually set out the condition for a good classification.
\begin_inset Newline newline
\end_inset

The first approach to augmentation didn’t produce the expected results.
 This was mainly caused by the high variety of data introduced by it and
 the complexity for the network to learn it.
 In fact, the high computational cost of the training didn’t allow us to
 run an high number of epochs.
 Thus, the benefits of augmentation were overcome by its disadvantages.
 After we introduced generator and by it optimized the memory usage, we
 found out that the augmentation provided the expected improvements.
\begin_inset Newline newline
\end_inset

There are still some open problems linked to this project.
 
\begin_inset Newline newline
\end_inset

First of all we have overcome the recognition of puppies due to the intrinsic
 difficulty of the task.
 Further works could reintroduce them with a correct classification.
\begin_inset Newline newline
\end_inset

Our task was to produce a binary classifier which could distinguish between
 a sea lion and the background.
 An extension to this could be a multiclass classifier which can effectively
 recognise among the classes of the original competition.
\begin_inset Newline newline
\end_inset

Another approach that could produce an improvement in the results is to
 exploit transfer learning from models trained with imageNet, for example,
 since they provide optimal performances in low level feature extraction
 (citation 
\begin_inset CommandInset citation
LatexCommand cite
key "Matt"
literal "false"

\end_inset

).
\begin_inset Newline newline
\end_inset

The last thing we imagine could work better is a direct object recognition
 approach without going through the classification task, however this would
 require a much more detailed ground truth (citation 
\begin_inset CommandInset citation
LatexCommand cite
key "CMR"
literal "false"

\end_inset

).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-1"

\end_inset

Krizhevsky, A., Sutskever, I., & Hinton, G.
 E.
 (2012).
 ImageNet classification with deep convolutional neural networks.
 In F.
 Pereira, C.
 J.
 C.
 Burges, L.
 Bottou, & K.
 Q.
 Weinberger (Eds.), Advances in neural information processing systems, 25
 (pp.
 1097–1105).
 Red Hook, NY: Curran.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset

Y.
 LeCun, B.
 Boser, J.
 Denker, D.
 Henderson, R.
 E.
 Howard, W.
 Hubbard, and L.
 D.
 Jackel.
 Backpropagation applied to hand-written zip code recognition.
 In Neural Computation, 1989.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-3"

\end_inset

Simonyan, K., & Zisserman, A.
 (2014).
 Very deep convolutional networks for large-scale image recognition.
 arXiv 1409.1556.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-4"

\end_inset

Karpathy, A.
 (2016).
 CS231n: Convolutional neural networks for visual recognition.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-5"

\end_inset

Hubel, D.
 H., & Wiesel, T.
 N.
 (1959).
 Receptive fields of single neurones in the cat’s striate cortex.
 Journal of Physiology, 148(1), 574–591.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-6"

\end_inset

Hubel, D.
 H., & Wiesel, T.
 N.
 (1962).
 Receptive fields, binocular interaction and functional architecture in
 the cat’s visual cortex.
 Journal of Physiology, 160(1), 106–154.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-7"

\end_inset

LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P.
 (1998).
 Gradient-based learning applied to document recognition.
 Proceedings of the IEEE, 86(11), 2278–2324.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-8"
literal "false"

\end_inset

LeCun, Y., Boser, B., Denker, J.
 S., Henderson, D., Howard, R.
 E., Hubbard, W., & Jackel, L.
 D.
 (1989a).
 Handwritten digit recognition with a back-propagation net- work.
 In D.
 S.
 Touretzky (Ed.), Advances in neural information processing systems, 2 (pp.
 396–404).
 Cambridge, MA: MIT Press.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-9"
literal "false"

\end_inset

LeCun, Y., Boser, B., Denker, J.
 S., Henderson, D., Howard, R.
 E., Hubbard, W., & Jackel, L.
 D.
 (1989b).
 Backpropagation applied to handwritten zip code recogni- tion.
 Neural Computation, 1(4), 541–551.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-10"
literal "false"

\end_inset

LeCun, Y., Bengio, Y., & Hinton, G.
 (2015).
 Deep learning.
 Nature, 521(7553), 436– 444.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-11"
literal "false"

\end_inset

Simard, P.
 Y., Steinkraus, D., & Platt, J.
 C.
 (2003, August).
 Best practices for convolutional neural networks applied to visual document
 analysis.
 In Proceedings of the 7th International Conference on Document Analysis
 and Recognition (vol.
 3, pp.
 958– 963).
 Washington, DC: IEEE Computer Society.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-12"
literal "false"

\end_inset

Hinton, G.
 E., Osindero, S., & Teh, Y.
 (2006).
 A fast learning algorithm for deep belief nets.
 Neural Computation, 18(7), 1527–1554.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-13"
literal "false"

\end_inset

Hinton, G.
 E., & Salakhutdinov, R.
 R.
 (2006).
 Reducing the dimensionality of data with neural networks.
 Science, 313(5786), 504–507.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-14"
literal "false"

\end_inset

Bengio, Y., Lamblin, P., Popovici, D., & Larochelle, H.
 (2006).
 Greedy layer-wise training of deep networks.
 In J.
 C.
 Platt, D.
 Koller, Y.
 Singer, & S.
 T.
 Roweis (Eds.), Advances in neural information processing systems, 19 (pp.
 2814–2822).
 Red Hook, NY: Curran.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-19"

\end_inset

Krizhevsky, A., Sutskever, I., & Hinton, G.
 E.
 (2012).
 ImageNet classification with deep convolutional neural networks.
 In F.
 Pereira, C.
 J.
 C.
 Burges, L.
 Bottou, & K.
 Q.
 Weinberger (Eds.), Advances in neural information processing systems, 25
 (pp.
 1097–1105).
 Red Hook, NY: Curran.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-20"

\end_inset

Deng, L., & Yu, D.
 (2014).
 Deep learning: Methods and applications.
 Foundations and Trends in Signal Processing, 7(3–4), 197–387.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-21"

\end_inset

Zeiler, M.
 D., & Fergus, R.
 (2014).
 Visualizing and understanding convolutional net- works.
 In Proceedings of the European Conference on Computer Vision (pp.
 818–833).
 Berlin: Springer.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-22"

\end_inset

Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., .
 .
 .
 Rabinovich, A.
 (2015).
 Going deeper with convolutions.
 In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognitio
n (pp.
 1–9).
 Los Alamitos, CA: IEEE Com- puter Society.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-23"

\end_inset

He, K., Zhang, X., Ren, S., & Sun, J.
 (2015a).
 Deep residual learning for image recog- nition.
 arXiv 1512.03385.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-24"

\end_inset

Xu, B., Wang, N., Chen, T., & Li, M.
 (2015).
 Empirical evaluation of rectified activations in convolutional network.
 arXiv 1505.00853v2.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-25"

\end_inset

Hinton, G.
 E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R.
 R.
 (2012).
 Improving neural networks by preventing co-adaptation of feature detectors.
 arXiv 1207.0580.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-26"

\end_inset

Zeiler, M.
 D., & Fergus, R.
 (2013).
 Stochastic pooling for regularization of deep convolu- tional neural networks.
 arXiv 1301.3557.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-27"

\end_inset

Glorot, X., & Bengio, Y.
 (2010).
 Understanding the difficulty of training deep feed-forward neural networks.
 In Proceedings of the 13th International Conference on Artificial Intelligence
 and Statistics (pp.
 249–256).
 jmlr.org/proceedings/papers/v9 /glorot10a/glorot10a.pdf
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-29"

\end_inset

P.
 Sermanet, D.
 Eigen, X.
 Zhang, M.
 Mathieu, R.
 Fergus, and Y.
 LeCun.
 Overfeat: Integrated recognition, localization and detection using convolutiona
l networks.
 In ICLR, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-30"

\end_inset

R.
 Girshick, J.
 Donahue, T.
 Darrell, and J.
 Malik.
 Rich feature hierarchies for accurate object detection and semantic segmentatio
n.
 In Computer Vision and Pattern Recognition, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-31"

\end_inset

P.
 Fischer, A.
 Dosovitskiy, and T.
 Brox.
 Descriptor matching with convolutional neural networks: a comparison to
 SIFT.
 CoRR, abs/1405.5769, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-32"

\end_inset

J.
 Long, N.
 Zhang, and T.
 Darrell.
 Do convnets learn correspondence? In NIPS, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-33"

\end_inset

N.
 Zhang, J.
 Donahue, R.
 Girshick, and T.
 Darrell.
 Part- based r-cnns for fine-grained category detection.
 In Computer Vision–ECCV 2014, pages 834–849.
 Springer, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-34"

\end_inset

F.
 Ning, D.
 Delhomme, Y.
 LeCun, F.
 Piano, L.
 Bottou, and P.
 E.
 Barbano.
 Toward automatic phenotyping of developing embryos from videos.
 Image Processing, IEEE Transactions on, 14(9):1360–1371, 2005.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-35"

\end_inset

D.C.Ciresan,A.Giusti,L.M.Gambardella,andJ.Schmid- huber.
 Deep neural networks segment neuronal membranes in electron microscopy
 images.
 In NIPS, pages 2852–2860, 2012.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-36"

\end_inset

C.
 Farabet, C.
 Couprie, L.
 Najman, and Y.
 LeCun.
 Learning hierarchical features for scene labeling.
 Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2013.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-37"

\end_inset

P.
 H.
 Pinheiro and R.
 Collobert.
 Recurrent convolutional neural networks for scene labeling.
 In ICML, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-38"

\end_inset

B.
 Hariharan, P.
 Arbela ́ez, R.
 Girshick, and J.
 Malik.
 Simul- taneous detection and segmentation.
 In European Confer- ence on Computer Vision (ECCV), 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-39"

\end_inset

S.
 Gupta, R.
 Girshick, P.
 Arbelaez, and J.
 Malik.
 Learning rich features from RGB-D images for object detection and segmentation.
 In ECCV.
 Springer, 2014.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-40"

\end_inset

Y.
 Ganin and V.
 Lempitsky.
 N4-fields: Neural network nearest neighbor fields for image transforms.
 In ACCV, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-41"

\end_inset

J.
 Long, E.
 Shelhamer and T.
 Darrel.
 Fully Convolutional Networks for Semantic Segmentation.
 In IEEE Xplore, 2015.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-42"

\end_inset

B.
 Hariharan, P.
 Arbela ́ez, R.
 Girshick, and J.
 Malik.
 Hypercolumns for object segmentation and fine-grained localization.
 In Computer Vision and Pattern Recognition, 2015.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-43"

\end_inset

J.
 Tompson, A.
 Jain, Y.
 LeCun, and C.
 Bregler.
 Joint training of a convolutional network and a graphical model for human
 pose estimation.
 CoRR, abs/1406.2984, 2014.
\end_layout

\end_body
\end_document
