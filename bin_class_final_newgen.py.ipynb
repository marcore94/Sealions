{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from skimage.transform import rotate, resize, SimilarityTransform, warp\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (96, 96, 3)\n",
    "IM_HEIGHT = 96\n",
    "IM_WIDTH = 96\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIMIZER = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "SL_TRAIN_SIZE = 40411\n",
    "SL_VALIDATION_SIZE = 9668\n",
    "SL_TEST_SIZE = 13539\n",
    "EPOCHS = 25\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "STEPS_PER_EPOCH = (2 * SL_TRAIN_SIZE) // BATCH_SIZE + 1\n",
    "VALIDATION_STEPS_PER_EPOCH = (2 * SL_VALIDATION_SIZE) // BATCH_SIZE + 1\n",
    "MAX_EPOCHS_WITH_SAME_DATA_SET = 5\n",
    "\n",
    "TRAIN_PATH = \"./data_set/train/\"\n",
    "VALIDATION_PATH = \"./data_set/validation/\"\n",
    "TEST_PATH = \"./data_set/test/\"\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_2_model.h5\"\n",
    "\n",
    "MR_CKPT_PATH = \"./binary_classifier/net_2_most_recent_checkpoint.hdf5\"\n",
    "CB_CKPT_PATH = \"./binary_classifier/net_2_current_best_checkpoint.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    rescale=1./255,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    sl_lst_tmp = os.listdir(TRAIN_PATH + '0_sea_lions')\n",
    "    bkg_lst_tmp = os.listdir(TRAIN_PATH + '1_background')\n",
    "    for i in range(EPOCHS // MAX_EPOCHS_WITH_SAME_DATA_SET):\n",
    "        Y_train = np.array([[1, 0]]*SL_TRAIN_SIZE + [[0, 1]]*SL_TRAIN_SIZE)\n",
    "        img_lst = []\n",
    "        for name in sl_lst_tmp:\n",
    "            img = cv2.imread(TRAIN_PATH + '0_sea_lions/' + name)\n",
    "            img_lst.append(img)\n",
    "        for name in rand.sample(bkg_lst_tmp, SL_TRAIN_SIZE):\n",
    "            img_lst.append(cv2.imread(TRAIN_PATH + '1_background/' + name))\n",
    "        X_train = np.array(img_lst)\n",
    "        gen = train_datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE)\n",
    "        for j in range(MAX_EPOCHS_WITH_SAME_DATA_SET):\n",
    "            step = 0\n",
    "            for batch in gen:\n",
    "                yield batch\n",
    "                step += 1\n",
    "                if step >= STEPS_PER_EPOCH:\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data set\n",
    "X_validation = []\n",
    "Y_validation = []\n",
    "validation_set = []\n",
    "lst = os.listdir(VALIDATION_PATH + '0_sea_lions')\n",
    "for elem in lst:\n",
    "    validation_set.append(list((cv2.imread(VALIDATION_PATH + '0_sea_lions/' + elem), 'sea_lion')))\n",
    "lst = os.listdir(VALIDATION_PATH + '1_background')\n",
    "for elem in lst:\n",
    "    validation_set.append(list((cv2.imread(VALIDATION_PATH + '1_background/' + elem), 'background')))\n",
    "rand.shuffle(validation_set)\n",
    "for data in validation_set:\n",
    "    X_validation.append(data[0])\n",
    "    if data[1] == 'sea_lion':\n",
    "        Y_validation.append([1, 0])\n",
    "    else:\n",
    "        Y_validation.append([0, 1])\n",
    "\n",
    "X_validation = np.array(X_validation, copy=False)\n",
    "# Convert data types and normalize values\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_validation /= 255\n",
    "Y_validation = np.array(Y_validation, copy=False)\n",
    "\n",
    "# Free memory\n",
    "lst = []\n",
    "validation_set = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.accuracies = []\n",
    "        self.val_acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.accuracies.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "\n",
    "history = History()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointers\n",
    "\n",
    "# most recent checkpoint\n",
    "mr_checkpointer = ModelCheckpoint(filepath=MR_CKPT_PATH, verbose=1, save_best_only=False)\n",
    "# current best checkpoint\n",
    "cb_checkpointer = ModelCheckpoint(filepath=CB_CKPT_PATH, verbose=1, save_best_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "# Fit model on training data\n",
    "results = model.fit_generator(\n",
    "    train_generator(),\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validation, Y_validation),\n",
    "    workers=8,\n",
    "    max_queue_size=50,\n",
    "    callbacks=[mr_checkpointer, cb_checkpointer, history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "h_df = pd.DataFrame({'acc': history.accuracies,\n",
    "                     'val_acc': history.val_acc,\n",
    "                     'loss': history.losses,\n",
    "                     'val_loss': history.val_losses})\n",
    "\n",
    "h_df.to_csv(\"./metrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "\n",
    "# serialize model to HDF5\n",
    "model.save(MODEL_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
